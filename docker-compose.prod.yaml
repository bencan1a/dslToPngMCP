# =============================================================================
# Docker Compose - Production Environment
# =============================================================================
# Multi-container orchestration for DSL to PNG MCP Server
# Production setup with security, performance optimizations, and monitoring
# =============================================================================

version: '3.8'

# =============================================================================
# SERVICES DEFINITION
# =============================================================================
services:
  
  # ---------------------------------------------------------------------------
  # Redis - Cache and Message Queue
  # ---------------------------------------------------------------------------
  redis:
    build:
      context: ./docker/redis
      dockerfile: Dockerfile
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
    image: dsl-png/redis:${VERSION:-latest}
    container_name: dsl-redis-prod
    hostname: redis
    restart: unless-stopped
    networks:
      - backend
      - browser-network
    volumes:
      - redis_data:/data/redis
      - redis_logs:/var/log/redis
      - ./docker/redis/redis-prod.conf:/etc/redis/redis.conf:ro
    environment:
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
    secrets:
      - redis_password
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
      update_config:
        parallelism: 1
        delay: 10s
        order: stop-first
    healthcheck:
      test: ["CMD", "/usr/local/bin/health-check.sh"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=redis,environment=production"

  # ---------------------------------------------------------------------------
  # MCP Server - Protocol Handling Service
  # ---------------------------------------------------------------------------
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile
      target: mcp-server
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/mcp-server:${VERSION:-latest}
    container_name: dsl-mcp-server-prod
    hostname: mcp-server
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - backend
    volumes:
      - mcp_logs:/app/logs
      - ./docker/config/mcp-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_MCP_HOST=0.0.0.0
      - DSL_PNG_MCP_PORT=3001
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      update_config:
        parallelism: 1
        delay: 10s
        order: stop-first
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(5); s.connect(('localhost', 3001)); s.close()"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=mcp-server,environment=production"

  # ---------------------------------------------------------------------------
  # FastAPI Server - REST API Service (2 replicas)
  # ---------------------------------------------------------------------------
  fastapi-server-1:
    build:
      context: .
      dockerfile: Dockerfile
      target: fastapi-server
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/fastapi-server:${VERSION:-latest}
    container_name: dsl-fastapi-1-prod
    hostname: fastapi-server-1
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      mcp-server:
        condition: service_healthy
    networks:
      - backend
      - frontend
    volumes:
      - fastapi_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/fastapi-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_HOST=0.0.0.0
      - DSL_PNG_PORT=8000
      - DSL_PNG_WORKERS=2
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - INSTANCE_ID=1
    secrets:
      - app_secret_key
    expose:
      - "8000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      update_config:
        parallelism: 1
        delay: 30s
        order: start-first
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=fastapi-server,instance=1,environment=production"

  fastapi-server-2:
    build:
      context: .
      dockerfile: Dockerfile
      target: fastapi-server
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/fastapi-server:${VERSION:-latest}
    container_name: dsl-fastapi-2-prod
    hostname: fastapi-server-2
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      mcp-server:
        condition: service_healthy
    networks:
      - backend
      - frontend
    volumes:
      - fastapi_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/fastapi-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_HOST=0.0.0.0
      - DSL_PNG_PORT=8000
      - DSL_PNG_WORKERS=2
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - INSTANCE_ID=2
    secrets:
      - app_secret_key
    expose:
      - "8000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      update_config:
        parallelism: 1
        delay: 30s
        order: start-first
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=fastapi-server,instance=2,environment=production"

  # ---------------------------------------------------------------------------
  # Celery Workers - Background Task Processing (4 replicas)
  # ---------------------------------------------------------------------------
  celery-worker-1:
    build:
      context: .
      dockerfile: Dockerfile
      target: celery-worker
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/celery-worker:${VERSION:-latest}
    container_name: dsl-celery-1-prod
    hostname: celery-worker-1
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      playwright-browsers:
        condition: service_healthy
    networks:
      - backend
      - browser-network
    volumes:
      - celery_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/celery-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - WORKER_ID=1
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      update_config:
        parallelism: 2
        delay: 60s
        order: stop-first
    healthcheck:
      test: ["CMD", "celery", "-A", "src.core.queue.tasks", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 45s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-worker,worker=1,environment=production"

  celery-worker-2:
    build:
      context: .
      dockerfile: Dockerfile
      target: celery-worker
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/celery-worker:${VERSION:-latest}
    container_name: dsl-celery-2-prod
    hostname: celery-worker-2
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      playwright-browsers:
        condition: service_healthy
    networks:
      - backend
      - browser-network
    volumes:
      - celery_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/celery-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - WORKER_ID=2
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      update_config:
        parallelism: 2
        delay: 60s
        order: stop-first
    healthcheck:
      test: ["CMD", "celery", "-A", "src.core.queue.tasks", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 45s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-worker,worker=2,environment=production"

  celery-worker-3:
    build:
      context: .
      dockerfile: Dockerfile
      target: celery-worker
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/celery-worker:${VERSION:-latest}
    container_name: dsl-celery-3-prod
    hostname: celery-worker-3
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      playwright-browsers:
        condition: service_healthy
    networks:
      - backend
      - browser-network
    volumes:
      - celery_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/celery-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - WORKER_ID=3
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      update_config:
        parallelism: 2
        delay: 60s
        order: stop-first
    healthcheck:
      test: ["CMD", "celery", "-A", "src.core.queue.tasks", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 45s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-worker,worker=3,environment=production"

  celery-worker-4:
    build:
      context: .
      dockerfile: Dockerfile
      target: celery-worker
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/celery-worker:${VERSION:-latest}
    container_name: dsl-celery-4-prod
    hostname: celery-worker-4
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      playwright-browsers:
        condition: service_healthy
    networks:
      - backend
      - browser-network
    volumes:
      - celery_logs:/app/logs
      - png_storage:/app/storage
      - html_temp:/app/tmp
      - ./docker/config/celery-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_REDIS_URL=redis://redis:6379/0
      - DSL_PNG_CELERY_BROKER_URL=redis://redis:6379/1
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - WORKER_ID=4
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      update_config:
        parallelism: 2
        delay: 60s
        order: stop-first
    healthcheck:
      test: ["CMD", "celery", "-A", "src.core.queue.tasks", "inspect", "ping"]
      interval: 60s
      timeout: 10s
      retries: 5
      start_period: 45s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=celery-worker,worker=4,environment=production"

  # ---------------------------------------------------------------------------
  # Playwright Browser Pool Service
  # ---------------------------------------------------------------------------
  playwright-browsers:
    build:
      context: .
      dockerfile: Dockerfile
      target: playwright-browsers
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
        VERSION: ${VERSION}
    image: dsl-png/playwright-browsers:${VERSION:-latest}
    container_name: dsl-browsers-prod
    hostname: playwright-browsers
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - browser-network
    volumes:
      - browser_cache:/app/.cache
      - html_temp:/app/tmp
      - playwright_logs:/app/logs
      - ./docker/config/playwright-prod.env:/app/.env:ro
    environment:
      - DSL_PNG_ENVIRONMENT=production
      - DSL_PNG_DEBUG=false
      - DSL_PNG_PLAYWRIGHT_HEADLESS=true
      - DSL_PNG_BROWSER_POOL_SIZE=5
      - DSL_PNG_LOG_LEVEL=INFO
      - DSL_PNG_SECRET_KEY_FILE=/run/secrets/app_secret_key
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
    secrets:
      - app_secret_key
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      update_config:
        parallelism: 1
        delay: 120s
        order: stop-first
    healthcheck:
      test: ["CMD", "python", "-c", "from playwright.async_api import async_playwright; import asyncio; asyncio.run(async_playwright().start())"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=playwright-browsers,environment=production"

  # ---------------------------------------------------------------------------
  # Nginx Reverse Proxy and Load Balancer
  # ---------------------------------------------------------------------------
  nginx-proxy:
    build:
      context: ./docker/nginx
      dockerfile: Dockerfile
      args:
        BUILD_DATE: ${BUILD_DATE}
        VCS_REF: ${VCS_REF}
    image: dsl-png/nginx-proxy:${VERSION:-latest}
    container_name: dsl-nginx-prod
    hostname: nginx-proxy
    restart: unless-stopped
    depends_on:
      fastapi-server-1:
        condition: service_healthy
      fastapi-server-2:
        condition: service_healthy
    networks:
      - frontend
    volumes:
      - nginx_logs:/var/log/nginx
      - png_storage:/var/www/static/png:ro  # Serve PNG files directly
      - ./docker/nginx/conf.d/prod.conf:/etc/nginx/conf.d/default.conf:ro
      - ./docker/nginx/html:/var/www/html:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro  # Let's Encrypt certificates
    environment:
      - NGINX_ENV=production
      - BACKEND_SERVERS=fastapi-server-1:8000,fastapi-server-2:8000
      - DOMAIN_NAME=${DOMAIN_NAME:-localhost}
    ports:
      - "80:80"    # HTTP
      - "443:443"  # HTTPS
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 64M
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=nginx-proxy,environment=production"

  # ---------------------------------------------------------------------------
  # Monitoring and Observability (Optional)
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: dsl-prometheus-prod
    hostname: prometheus
    restart: unless-stopped
    networks:
      - backend
    volumes:
      - prometheus_data:/prometheus
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:10.1.0
    container_name: dsl-grafana-prod
    hostname: grafana
    restart: unless-stopped
    depends_on:
      - prometheus
    networks:
      - backend
      - frontend
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_password
      - GF_USERS_ALLOW_SIGN_UP=false
    secrets:
      - grafana_password
    ports:
      - "3000:3000"
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    profiles:
      - monitoring

# =============================================================================
# NETWORKS DEFINITION
# =============================================================================
networks:
  frontend:
    driver: bridge
    name: dsl-frontend-prod
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/24
          gateway: 172.30.0.1

  backend:
    driver: bridge
    name: dsl-backend-prod
    internal: true  # No external access
    ipam:
      driver: default
      config:
        - subnet: 172.31.0.0/24
          gateway: 172.31.0.1

  browser-network:
    driver: bridge
    name: dsl-browser-prod
    internal: true  # No external access
    ipam:
      driver: default
      config:
        - subnet: 172.32.0.0/24
          gateway: 172.32.0.1

# =============================================================================
# VOLUMES DEFINITION
# =============================================================================
volumes:
  # Persistent volumes with backup configurations
  png_storage:
    name: dsl-png-storage-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PNG_STORAGE_PATH:-/opt/dsl-png/storage/png}

  redis_data:
    name: dsl-redis-data-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${REDIS_DATA_PATH:-/opt/dsl-png/data/redis}

  nginx_logs:
    name: dsl-nginx-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/nginx

  # Temporary volumes
  html_temp:
    name: dsl-html-temp-prod
    driver: local

  browser_cache:
    name: dsl-browser-cache-prod
    driver: local

  # Log volumes
  mcp_logs:
    name: dsl-mcp-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/mcp

  fastapi_logs:
    name: dsl-fastapi-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/fastapi

  celery_logs:
    name: dsl-celery-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/celery

  playwright_logs:
    name: dsl-playwright-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/playwright

  redis_logs:
    name: dsl-redis-logs-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${LOG_PATH:-/opt/dsl-png/logs}/redis

  # Monitoring volumes
  prometheus_data:
    name: dsl-prometheus-data-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MONITORING_DATA_PATH:-/opt/dsl-png/monitoring}/prometheus

  grafana_data:
    name: dsl-grafana-data-prod
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MONITORING_DATA_PATH:-/opt/dsl-png/monitoring}/grafana

# =============================================================================
# SECRETS DEFINITION
# =============================================================================
secrets:
  app_secret_key:
    file: ./secrets/app_secret_key.txt
  redis_password:
    file: ./secrets/redis_password.txt
  grafana_password:
    file: ./secrets/grafana_password.txt

# =============================================================================
# CONFIGS DEFINITION
# =============================================================================
configs:
  nginx_prod_config:
    file: ./docker/nginx/conf.d/prod.conf
  redis_prod_config:
    file: ./docker/redis/redis-prod.conf